{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a7ca6-68bf-4c45-b57f-5a548a07442b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "from numba import cuda\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datasets import Dataset\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import random\n",
    "import outlines\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import pipeline as transformers_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151edda9-e256-47d2-9f1c-4049cc038df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT AND PREPARE DATASET\n",
    "path = '' # Specify the path to your dataset file\n",
    "\n",
    "\n",
    "ds = pd.read_csv(path)\n",
    "\n",
    "dataset = Dataset.from_pandas(ds)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f1215-ce54-46e6-980c-681188d47683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "hf_token = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
    "pipeline = transformers_pipeline(   \"text-generation\", \n",
    "                                    model = model_name,\n",
    "                                    torch_dtype= torch.float32,\n",
    "                                    device_map=\"auto\",\n",
    "                                    token=hf_token\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb378d-3786-44e6-a0fe-e66bdfc2d5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT DEFINTIONS - STEP 1\n",
    "def_step_1 = {    \"NO\":\"\",\n",
    "                \"FtW\":\"Hate is defined as abusive speech targeting specific group characteristics, such as ethnic origin, religion, gender, or sexual orientation.\",\n",
    "                \"OL\":\"Hate Speech is considered any kind of content that conveys malevolent intentions toward a group or an individual.\",\n",
    "                \"HSB\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual, and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDFoC\":\"Hate speech is considered any kind of content or communication expressed using language (written or spoken) or actions,  that convey malevolent intentions toward a group or an individual, and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDPC\":\"Hate speech is considered any kind of content that conveys malevolent intentions such as statements of inferiority, aversion, cursing, calls for exclusion, threaten, harass or violence, and directed toward a group or an individual, and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDT\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDFoC_EDT\":\"Hate speech is considered any kind of content or communication expressed using language (written or spoken) or actions,  that convey malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDFoC_EDPC\":\"Hate speech is considered any kind of content or communication expressed using language (written or spoken) or actions, that convey malevolent intentions such as statements of inferiority, aversion, cursing, calls for exclusion, threaten, harass or violence, and directed toward a group or an individual and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDT_EDPC\":\"Hate speech is considered any kind of content that conveys malevolent intentions such as statements of inferiority, aversion, cursing, calls for exclusion, threaten, harass or violence, toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members.\",\n",
    "                \"HSB_EDFoC_EDPC_EDT\":\"Hate speech is considered any kind of content or communication expressed using language (written or spoken) or actions,  that conveys malevolent intentions such as statements of inferiority, aversion, cursing, calls for exclusion, threaten, harass or violence, toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members.\"\n",
    "                }\n",
    "\n",
    "def_step_2 = {\"HSB_EDT_LAA\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics.\",\n",
    "            \"HSB_EDT_LAA_PI\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. The outcome of Hate Speech could be the promotion of division among people, undermining of social cohesion in communities, inciting others to commit violence or discrimination, and could have consequences for individuals’ health and safety.\",\n",
    "            \"HSB_EDT_LAA_Exc\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. However, even if it is offensive, it is not considered Hate Speech any content that attacks a person’s personality traits, ideas, or opinions\",\n",
    "            \"HSB_EDT_LAA_IHS\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. Hate Speech can also be implicit, portrayed as an indirect or coded language that uses Irony, Stereotypes, or Misinformation.\",\n",
    "            \"HSB_EDT_LAA_PI_Exc\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. The outcome of Hate Speech could be the promotion of division among people, undermining of social cohesion in communities, inciting others to commit violence or discrimination, and could have consequences for individuals’ health and safety. However, even if it is offensive, it is not considered Hate Speech any content that attacks a person’s personality traits, ideas, or opinions.\",\n",
    "            \"HSB_EDT_LAA_Exc_IHS\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. Hate Speech can also be implicit, portrayed as an indirect or coded language that uses Irony, Stereotypes, or Misinformation. However, even if it is offensive, it is not considered Hate Speech any content that attacks a person’s personality traits, ideas, or opinions.\",\n",
    "            \"HSB_EDT_LAA_PI_IHS\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. The outcome of Hate Speech could be the promotion of division among people, undermining of social cohesion in communities, inciting others to commit violence or discrimination, and could have consequences for individuals’ health and safety. Hate Speech can also be implicit, portrayed as an indirect or coded language that uses Irony, Stereotypes, or Misinformation.\",\n",
    "            \"HSB_EDT_LAA_PI_IHS_Exc\":\"Hate speech is considered any kind of content that conveys malevolent intentions toward a group or an individual which is, or thought to be, a member of that group, and motivated by inherent characteristics that are attributed to that group and shared among its members such as race, color, ethnicity, gender, sexual orientation, nationality, religion, disability, social status, health conditions, or other characteristics. The outcome of Hate Speech could be the promotion of division among people, undermining of social cohesion in communities, inciting others to commit violence or discrimination, and could have consequences for individuals’ health and safety. Hate Speech can also be implicit, portrayed as an indirect or coded language that uses Irony, Stereotypes, or Misinformation. However, even if it is offensive, it is not considered Hate Speech any content that attacks a person’s personality traits, ideas, or opinions.\"\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27c43e-e00e-499a-92c8-7e53cbc80180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#PREPARE DATAPOINTS\n",
    "\n",
    "model_inputs = []\n",
    "labels = []\n",
    "instructions = \"Classify if the following text is considered hate speech or not hate speech:\\n\"\\\n",
    "              \"[TEXT]\\n\"\\\n",
    "              \"Please answer ONLY with HS if it is hate speech or NHS if it is not.\"\n",
    "\n",
    "for datapoint in tqdm(dataset):\n",
    "    model_input = instructions\n",
    "    model_input = model_input.replace(\"[TEXT]\", datapoint['text'])\n",
    "    \n",
    "\n",
    "    if datapoint['label'] == 'hate':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "    model_inputs.append(model_input)\n",
    "print(model_inputs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe99d7c-5d96-4a0d-b65b-f3e0019723e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metriche(predictions,labels):\n",
    "\n",
    "    predictions = [np.nan if x == 'NaN' else x for x in predictions]\n",
    "\n",
    "    # Convert predictions to numpy array to handle NaN values\n",
    "    predictions = np.array(predictions, dtype=float)  # Convert to float array for NaN handling\n",
    "\n",
    "    # Replace NaN values with a default value (e.g., 0) if needed\n",
    "    predictions[np.isnan(predictions)] = 0  # Replace NaN with 0 (or any other appropriate value)\n",
    "\n",
    "    # Calculate precision (handling NaN appropriately)\n",
    "    precision = precision_score(labels, predictions, average='binary', zero_division=0)\n",
    "\n",
    "    # Calculate recall (handling NaN appropriately)\n",
    "    recall = recall_score(labels, predictions, average='binary', zero_division=0)\n",
    "\n",
    "    # Calculate F1 score (handling NaN appropriately)\n",
    "    f1 = f1_score(labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b713cf9-303f-475e-84f9-4a61c679cc28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DEFINITION IN USER PROMPT\n",
    "\n",
    "def runner2(model_inputs, labels, num_runs, id_def, definition, sample):\n",
    "    results = []\n",
    "\n",
    "    for j in range(num_runs):  \n",
    "        if sample == 'all' or sample >= 3901:\n",
    "            sample = 3901\n",
    "        else:\n",
    "            model_inputs = model_inputs[:sample]\n",
    "            labels = labels[:sample]\n",
    "\n",
    "        completions = []\n",
    "        responses = []\n",
    "        \n",
    "        #if definition == '':\n",
    "        system_prompt = ''\n",
    "        #else:\n",
    "        #    system_prompt = 'Given the following definition of Hate Speech: ' + str(definition)\n",
    "            \n",
    "        model_prompt = '''<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "                         {{ [SYSTEM_PROMPT] }}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "                        {{ [USER_MESSAGE] }}<|eot_id|><|start_header_id|>assistant<|end_header_id|>'''\n",
    "\n",
    "        \n",
    "        \n",
    "        for i, inputtone in enumerate(tqdm(model_inputs)): \n",
    "            \n",
    "            if id_def == 'NO':\n",
    "                tot_in = inputtone\n",
    "            else:\n",
    "                tot_in = 'Given the following definition of Hate Speech: \\n' + str(definition) +'\\n' + inputtone \n",
    "                \n",
    "            model_in = model_prompt.replace(\"[SYSTEM_PROMPT]\", system_prompt)\n",
    "            model_in = model_in.replace(\"[USER_MESSAGE]\", tot_in)\n",
    "            completion = pipeline(\n",
    "                                    model_in,\n",
    "                                    do_sample=True,\n",
    "                                    num_return_sequences=1,\n",
    "                                    pad_token_id=tokenizer.eos_token_id,\n",
    "                                    max_new_tokens=20,\n",
    "                                    temperature = 0.95,\n",
    "                                    return_full_text=False\n",
    "                                    )\n",
    "\n",
    "            response_complete = completion[0]['generated_text']\n",
    "            response = response_complete\n",
    "            if \"Answer\" in response_complete:\n",
    "                response = response.split(\"Answer\")[1]\n",
    "            response = response.strip(\": \\n\")\n",
    "            responses.append(response)\n",
    "            completions.append(completion[0])\n",
    "\n",
    "\n",
    "            predictions = []\n",
    "            for response in responses:\n",
    "                cleaned_response = response.strip().upper()\n",
    "                if re.search(r'\\bHS\\b', cleaned_response):\n",
    "                    predictions.append(1)\n",
    "                elif re.search(r'\\bNHS\\b', cleaned_response):\n",
    "                    predictions.append(0)\n",
    "                else:\n",
    "                    predictions.append('NaN')\n",
    "                    #print(cleaned_response)\n",
    "\n",
    "\n",
    "\n",
    "        num = j+1\n",
    "        print('Run number:', num, 'With definition: ', id_def)     \n",
    "        numeratore = sum(1 for p,l in zip(predictions,labels) if p ==l)\n",
    "        denominatore = len(predictions)\n",
    "        acc = numeratore/denominatore\n",
    "        print('Accuracy: ', acc)\n",
    "        nans = sum(1 for p in predictions if p =='NaN')\n",
    "        print('Numbers of non-answer: ',nans)\n",
    "        if denominatore == nans:\n",
    "            acc_no_nans = 0\n",
    "        else:\n",
    "            acc_no_nans = numeratore/(denominatore-nans)\n",
    "        print('Accuracy without no-answers: ', acc_no_nans)\n",
    "        \n",
    "        \n",
    "    \n",
    "        precision, recall, f1 = metriche(predictions, labels)\n",
    "\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "        print('F1 Score: ', f1)\n",
    "        \n",
    "        results.append({'Run': num,\n",
    "                        'Model': model_name, \n",
    "                        'ID_def': id_def,\n",
    "                        'Accuracy': acc, \n",
    "                        'NaNs': nans, \n",
    "                        'Acc_No_Nans': acc_no_nans, \n",
    "                        'Precision': precision, \n",
    "                        'Recall': recall, \n",
    "                        'F1': f1 ,\n",
    "                        'Input': dataset['text'],\n",
    "                        'Responses': responses,\n",
    "                        'Predictions': predictions, \n",
    "                        'Labels': labels, \n",
    "                        'Definition': definition,\n",
    "                        'Target': dataset['target'],\n",
    "                        'Type': dataset['type']})\n",
    "                \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415440f8-cb39-4417-a282-671853e6f10f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ALL THE DEFINITIONS\n",
    "sample = 'all'\n",
    "num_runs = 3\n",
    "def_id = None\n",
    "definition = None\n",
    "step = 1\n",
    "\n",
    "results = []\n",
    "\n",
    "if step == '1':\n",
    "    def_dict = def_step_1\n",
    "    step_name = 'step1'\n",
    "elif step == '2':\n",
    "    def_dict = def_step_2\n",
    "    step_name = 'step2'\n",
    "\n",
    "\n",
    "for k, v in def_dict.items():\n",
    "    def_id = k\n",
    "    definition = v\n",
    "    result = runner2(model_inputs, labels, num_runs=num_runs, id_def=def_id, definition=definition, sample=sample)\n",
    "    results.extend(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a8ecf-086f-4547-9d30-7541ee6307f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CREATE DF AND SAVE\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "csv_file_path = '../Outputs/LLama3_FtW_step'+ str(step) +'.csv'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)  # Set index=False to exclude row numbers in the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3a6d6-8f88-4e59-b178-a4bccbca7dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = '../Outputs/LLama3_FtW_step'+ str(step) +'.csv'\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Group the DataFrame by 'id_def' and calculate the mean of 'Accuracy' within each group\n",
    "avg_accuracy_per_id = df.groupby('ID_def')['F1'].mean().reset_index()\n",
    "\n",
    "avg_accuracy_per_id_sorted = avg_accuracy_per_id.sort_values(by='F1', ascending=False)\n",
    "\n",
    "# Display the average accuracy for each id_def\n",
    "print(avg_accuracy_per_id_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144f602-e347-473f-b789-354eec826f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "65037a40e934b14503404e412a10b71c3933ce023a0cd46a7e5dc61bdd2dc8b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
